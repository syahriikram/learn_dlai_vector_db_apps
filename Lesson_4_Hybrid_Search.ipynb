{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8124bfdf-bd97-4814-8c80-560f4e0d2334",
   "metadata": {},
   "source": [
    "# Lesson 4 - Hybrid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41241c42",
   "metadata": {},
   "source": [
    "### Import the Needed Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3c06eb-524a-4b35-9db2-f440392eccfc",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a61ece-03da-4e87-9d0a-d99e494bbb71",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pinecone_text.sparse import BM25Encoder\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from DLAIUtils import Utils\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea1366a-9ff9-4471-8eea-c88227b22789",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "utils = Utils()\n",
    "PINECONE_API_KEY = utils.get_pinecone_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52794a31",
   "metadata": {},
   "source": [
    "### Setup Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff87e06-9822-4528-82af-0c73ae11059d",
   "metadata": {
    "height": 302
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "utils = Utils()\n",
    "INDEX_NAME = utils.create_dlai_index_name('dl-ai')\n",
    "\n",
    "pinecone = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
    "  pinecone.delete_index(INDEX_NAME)\n",
    "pinecone.create_index(\n",
    "  INDEX_NAME,\n",
    "  dimension=512,\n",
    "  metric=\"dotproduct\",\n",
    "  spec=ServerlessSpec(cloud='aws', region='us-west-2')\n",
    ")\n",
    "index = pinecone.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257830a5",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9ea178-7737-4916-8eaa-24a824b41cb0",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfeae0bc5a54e6982515c383dc92889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/867 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666c2eb9b7c34f93958003fb933b5c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4141108e2c934f4f86daa7ee3b2d3bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/136M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6185ba838254a07aa71b910bbce0a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/135M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef48827d066447bb4efc5b70e4b85af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318d429a7f004c96bc9e7c1baf45e10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/44072 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'gender', 'masterCategory', 'subCategory', 'articleType', 'baseColour', 'season', 'year', 'usage', 'productDisplayName', 'image'],\n",
       "    num_rows: 44072\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion = load_dataset(\n",
    "    \"ashraq/fashion-product-images-small\",\n",
    "    split=\"train\"\n",
    ")\n",
    "fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "909a738b-1c70-4b0d-8566-097d514b404d",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=60x80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = fashion['image']\n",
    "metadata = fashion.remove_columns('image')\n",
    "images[900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15faca59-729e-4cd4-9fc3-00feea488c9c",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "metadata = metadata.to_pandas()\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82acbbac",
   "metadata": {},
   "source": [
    "### Create the Sparse Vector Using BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "798ac46a-acb8-4eda-84a2-74f96e68d960",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd7662c42084307a14ebc9bff61799f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Turtle Check Men Navy Blue Shirt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = BM25Encoder()\n",
    "bm25.fit(metadata['productDisplayName'])\n",
    "metadata['productDisplayName'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb47ff8e-51d7-4dbb-b346-c1bde866e130",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indices': [23789636,\n",
       "  1830646559,\n",
       "  632192512,\n",
       "  931643408,\n",
       "  3905155331,\n",
       "  3828986392],\n",
       " 'values': [0.4449638258432887,\n",
       "  0.4449638258432887,\n",
       "  0.4449638258432887,\n",
       "  0.4449638258432887,\n",
       "  0.4449638258432887,\n",
       "  0.4449638258432887]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25.encode_queries(metadata['productDisplayName'][0])\n",
    "bm25.encode_documents(metadata['productDisplayName'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db48a9b1",
   "metadata": {},
   "source": [
    "### Create the Dense Vector Using CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91284667-e998-4c17-bcd9-d70c069e9bb2",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa54bf13a2e444fa7991b966af5c3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc5b59de2f74be19d5ea84e8d15a0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/config.json:   0%|          | 0.00/4.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b752824b06e48e8836aa9218d1afb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dd6eac73094e889f0184a535d5da35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c81cf5c50b4a79ab476a8045828731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0c8f307e394a4c83c0fe268e9a2844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366b41c3e2394456b68bf30da72a78f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/tokenizer_config.json:   0%|          | 0.00/604 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba67a51fc7c849069015695cf64bf7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b55010cacd645629ffacb9be2c740c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.91k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211c5fe270a04827af3d27b20738de74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69afd1af04044ce1ba7514b854a85d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 13:26:54.534272: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-26 13:26:54.534316: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-26 13:26:54.535641: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-26 13:26:54.542163: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-26 13:26:55.670837: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/clip-ViT-B-32', \n",
    "    device=device)\n",
    "model\n",
    "dense_vec = model.encode([metadata['productDisplayName'][0]])\n",
    "dense_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5b2755e-57b5-44d5-82de-3245f832182e",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44072"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fashion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e2c8f5",
   "metadata": {},
   "source": [
    "### Create Embeddings Using Sparse and Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb8ec3-ec58-4a5b-ace2-a48e8b671f58",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff1d7; padding:15px; \"> <b>(Note: <code>fashion_data_num = 1000</code>):</b> In this lab, we've initially set <code>fashion_data_num</code> to 1000 for speedier results, allowing you to observe the outcomes faster. Once you've done an initial run, consider increasing this value. You'll likely notice better and more relevant results.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca6852c5-0e99-450a-b6fe-5def9da89781",
   "metadata": {
    "height": 591
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11cf295298df4f32862bd55aa7f730ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m i_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(i\u001b[38;5;241m+\u001b[39mbatch_size, \u001b[38;5;28mlen\u001b[39m(fashion))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# extract metadata batch\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m meta_batch \u001b[38;5;241m=\u001b[39m \u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[i:i_end]\n\u001b[1;32m      9\u001b[0m meta_dict \u001b[38;5;241m=\u001b[39m meta_batch\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# concatinate all metadata field except for id and year to form a single string\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "fashion_data_num = 1000\n",
    "\n",
    "for i in tqdm(range(0, min(fashion_data_num,len(fashion)), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(fashion))\n",
    "    # extract metadata batch\n",
    "    meta_batch = metadata.iloc[i:i_end]\n",
    "    meta_dict = meta_batch.to_dict(orient=\"records\")\n",
    "    # concatinate all metadata field except for id and year to form a single string\n",
    "    meta_batch = [\" \".join(x) for x in meta_batch.loc[:, ~meta_batch.columns.isin(['id', 'year'])].values.tolist()]\n",
    "    # extract image batch\n",
    "    img_batch = images[i:i_end]\n",
    "    # create sparse BM25 vectors\n",
    "    sparse_embeds = bm25.encode_documents([text for text in meta_batch])\n",
    "    # create dense vectors\n",
    "    dense_embeds = model.encode(img_batch).tolist()\n",
    "    # create unique IDs\n",
    "    ids = [str(x) for x in range(i, i_end)]\n",
    "\n",
    "    upserts = []\n",
    "    # loop through the data and create dictionaries for uploading documents to pinecone index\n",
    "    for _id, sparse, dense, meta in zip(ids, sparse_embeds, dense_embeds, meta_dict):\n",
    "        upserts.append({\n",
    "            'id': _id,\n",
    "            'sparse_values': sparse,\n",
    "            'values': dense,\n",
    "            'metadata': meta\n",
    "        })\n",
    "    # upload the documents to the new hybrid index\n",
    "    index.upsert(upserts)\n",
    "\n",
    "# show index description after uploading the documents\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7487f3c",
   "metadata": {},
   "source": [
    "### Run Your Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "942d6de8-b967-4168-8406-b15c354bd58c",
   "metadata": {
    "height": 251
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"dark blue french connection jeans for men\"\n",
    "\n",
    "sparse = bm25.encode_queries(query)\n",
    "dense = model.encode(query).tolist()\n",
    "\n",
    "result = index.query(\n",
    "    top_k=14,\n",
    "    vector=dense,\n",
    "    sparse_vector=sparse,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6be9256b-889d-4803-9f0d-206bbba08ab7",
   "metadata": {
    "height": 353
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "from io import BytesIO\n",
    "from base64 import b64encode\n",
    "\n",
    "# function to display product images\n",
    "def display_result(image_batch):\n",
    "    figures = []\n",
    "    for img in image_batch:\n",
    "        b = BytesIO()\n",
    "        img.save(b, format='png')\n",
    "        figures.append(f'''\n",
    "            <figure style=\"margin: 5px !important;\">\n",
    "              <img src=\"data:image/png;base64,{b64encode(b.getvalue()).decode('utf-8')}\" style=\"width: 90px; height: 120px\" >\n",
    "            </figure>\n",
    "        ''')\n",
    "    return HTML(data=f'''\n",
    "        <div style=\"display: flex; flex-flow: row wrap; text-align: center;\">\n",
    "        {''.join(figures)}\n",
    "        </div>\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03260484-92f7-4394-9217-dc848d21e64f",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"display: flex; flex-flow: row wrap; text-align: center;\">\n",
       "        \n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_result(imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e32d0",
   "metadata": {},
   "source": [
    "### Scaling the Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc3ce832-f7c5-4592-ac91-18bc222f127c",
   "metadata": {
    "height": 353
   },
   "outputs": [],
   "source": [
    "def hybrid_scale(dense, sparse, alpha: float):\n",
    "    \"\"\"Hybrid vector scaling using a convex combination\n",
    "\n",
    "    alpha * dense + (1 - alpha) * sparse\n",
    "\n",
    "    Args:\n",
    "        dense: Array of floats representing\n",
    "        sparse: a dict of `indices` and `values`\n",
    "        alpha: float between 0 and 1 where 0 == sparse only\n",
    "               and 1 == dense only\n",
    "    \"\"\"\n",
    "    if alpha < 0 or alpha > 1:\n",
    "        raise ValueError(\"Alpha must be between 0 and 1\")\n",
    "    # scale sparse and dense vectors to create hybrid search vecs\n",
    "    hsparse = {\n",
    "        'indices': sparse['indices'],\n",
    "        'values':  [v * (1 - alpha) for v in sparse['values']]\n",
    "    }\n",
    "    hdense = [v * alpha for v in dense]\n",
    "    return hdense, hsparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a22e97f",
   "metadata": {},
   "source": [
    "### 1. More Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b4bb5-3f5c-4130-91c1-936442358939",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "question = \"dark blue french connection jeans for men\"\n",
    "#Closer to 0==more sparse, closer to 1==more dense\n",
    "hdense, hsparse = hybrid_scale(dense, sparse, alpha=1)\n",
    "result = index.query(\n",
    "    top_k=6,\n",
    "    vector=hdense,\n",
    "    sparse_vector=hsparse,\n",
    "    include_metadata=True\n",
    ")\n",
    "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
    "display_result(imgs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a710e-19b0-4f0f-83db-eaaba499b332",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "for x in result[\"matches\"]:\n",
    "    print(x[\"metadata\"]['productDisplayName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5109bec",
   "metadata": {},
   "source": [
    "### 2. More Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc0b53-c422-4ae4-b417-66862c1f757a",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "question = \"dark blue french connection jeans for men\"\n",
    "#Closer to 0==more sparse, closer to 1==more dense\n",
    "hdense, hsparse = hybrid_scale(dense, sparse, alpha=0)\n",
    "result = index.query(\n",
    "    top_k=6,\n",
    "    vector=hdense,\n",
    "    sparse_vector=hsparse,\n",
    "    include_metadata=True\n",
    ")\n",
    "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
    "display_result(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c22fc-426e-46f0-ae6c-e2c9c2a66ea9",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "for x in result[\"matches\"]:\n",
    "    print(x[\"metadata\"]['productDisplayName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac079a01",
   "metadata": {},
   "source": [
    "### More Dense or More Sparse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc6b0d9-646b-4f56-b6a7-a9a232ae5429",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "question = \"dark blue french connection jeans for men\"\n",
    "#Closer to 0==more sparse, closer to 1==more dense\n",
    "hdense, hsparse = hybrid_scale(dense, sparse, alpha=1)\n",
    "result = index.query(\n",
    "    top_k=6,\n",
    "    vector=hdense,\n",
    "    sparse_vector=hsparse,\n",
    "    include_metadata=True\n",
    ")\n",
    "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
    "display_result(imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a51bcf3-bb5a-447d-96cf-789bb798e665",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "for x in result[\"matches\"]:\n",
    "    print(x[\"metadata\"]['productDisplayName'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
